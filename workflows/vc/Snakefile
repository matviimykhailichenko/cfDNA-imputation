import pandas as pd
from pathlib import Path
import sys

snakefile_dir = Path(workflow.basedir).resolve()
repo_root = snakefile_dir.parents[1]
sys.path.insert(0, str(repo_root))

configfile: "config.yaml"

df = pd.read_csv(f"{repo_root}/doc/sample_manifest.csv")
SAMPLES = df.set_index("sample_id")["bam_path"].to_dict()
COVERAGES = [30,25,20,15,10]

rule all:
    input:
        expand(f"{config['results_dir']}" + "/{sample}.vcf.gz", sample=SAMPLES.keys())


from scripts.custom.helpers import get_highest_cov_bam, get_highest_cov_bai


rule call_variants:
    input:
        bam=lambda wc: get_highest_cov_bam(wc,data_dir=config["vc_data_dir"]),
        bai=lambda wc: get_highest_cov_bai(wc,data_dir=config["vc_data_dir"]),
        ref=config["reference"]
    output:
        vcf=f"{config['tmp_dir']}" + "/{sample}_tmp.vcf"
    threads: 20
    params:
        min_baseq=20,
        min_mapq=20,
        min_cov=12,
        min_qual=30
    conda:
        f'{repo_root}/shared/envs/lofreq.yaml'
    log:
        f'{config["results_dir"]}' + '/{sample}_variant_calling.log'
    shell:
        r"""
        set -euo pipefail

        lofreq call-parallel \
          --pp-threads {threads} \
          -f {input.ref} \
          --call-indels \
          -m {params.min_qual} \
          -q {params.min_baseq} \
          -Q {params.min_mapq} \
          -C {params.min_cov} \
          -o {output.vcf} \
          {input.bam} 2> {log}
        """


rule compress_index:
    input:
        vcf=f"{config['tmp_dir']}" + "/{sample}_tmp.vcf",
    output:
        comp_vcf=f"{config['results_dir']}" + "/{sample}.vcf.gz",
        tbi=f"{config['results_dir']}" + "/{sample}.vcf.gz.tbi"
    threads: 20
    conda:
        f'{repo_root}/shared/envs/htstools.yaml'
    log:
        f'{config["results_dir"]}' + '/{sample}_compress_index.log'
    shell:
        r"""
        set -euo pipefail
    
        bgzip -@ {threads} -f -c {input.vcf} > {output.comp_vcf}
        tabix -@ {threads} -f -p vcf {output.comp_vcf} 2>> {log}
        """
