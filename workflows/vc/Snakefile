import pandas as pd
from pathlib import Path
import sys

snakefile_dir = Path(workflow.basedir).resolve()
repo_root = snakefile_dir.parents[1]
sys.path.insert(0, str(repo_root))

configfile: "config.yaml"

df = pd.read_csv(f"{repo_root}/doc/sample_manifest.csv")
COVERAGES = [30,25,20,15,10]
testing = config['testing']
SAMPLES = df.set_index("sample_id")["bam_path"].to_dict() if not testing else {'test_sample':'/media/matvii/30c92328-1f20-448d-a014-902558a05393/galushka/sandbox/data/test_sample_30x.bam'}
data_dir = config["vc_data_dir"] if not testing else '/media/matvii/30c92328-1f20-448d-a014-902558a05393/galushka/sandbox/data'
tmp_dir = config["tmp_dir"] if not testing else '/media/matvii/30c92328-1f20-448d-a014-902558a05393/galushka/sandbox/tmp'
results_dir = config["results_dir"] if not testing else '/media/matvii/30c92328-1f20-448d-a014-902558a05393/galushka/sandbox/results'
reference = config['reference'] if not testing else config['reference_local']

rule all:
    input:
        expand(results_dir + "/{sample}.vcf.gz", sample=SAMPLES.keys())


from scripts.custom.helpers import get_highest_cov_bam, get_highest_cov_bai
from scripts.logging_ops import notify_bot

onstart:
    notify_bot("Snakemake had started.")

onsuccess:
    notify_bot("Snakemake had finished successfully.")

onerror:
    notify_bot("Snakemake had failed.")

rule call_variants:
    input:
        bam=lambda wc: get_highest_cov_bam(wc,data_dir=data_dir),
        bai=lambda wc: get_highest_cov_bai(wc,data_dir=data_dir),
        ref=reference
    output:
        vcf=tmp_dir + "/{sample}_tmp.vcf"
    threads: 20
    params:
        min_baseq=20,
        min_mapq=20,
        min_cov=12,
        min_qual=30
    conda:
        f'{repo_root}/shared/envs/lofreq.yaml'
    log:
        results_dir + '/{sample}_variant_calling.log'
    shell:
        r"""
        set -euo pipefail

        lofreq call-parallel \
          --pp-threads {threads} \
          -f {input.ref} \
          --call-indels \
          -m {params.min_qual} \
          -q {params.min_baseq} \
          -Q {params.min_mapq} \
          -C {params.min_cov} \
          -o {output.vcf} \
          {input.bam} 2> {log}
        """


rule compress_index:
    input:
        vcf=tmp_dir + "/{sample}_tmp.vcf",
    output:
        comp_vcf=results_dir + "/{sample}.vcf.gz",
        tbi=results_dir + "/{sample}.vcf.gz.tbi"
    threads: 20
    conda:
        f'{repo_root}/shared/envs/htstools.yaml'
    log:
        results_dir + '/{sample}_compress_index.log'
    shell:
        r"""
        set -euo pipefail
    
        bgzip -@ {threads} -f -c {input.vcf} > {output.comp_vcf}
        tabix -@ {threads} -f -p vcf {output.comp_vcf} 2>> {log}
        """
